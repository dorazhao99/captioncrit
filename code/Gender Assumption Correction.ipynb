{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gender Assumption Correction\n",
    "Used for Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, requests, io\n",
    "from pycocotools.coco import COCO\n",
    "import urllib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect Faces in MSCOCO Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sees whether a face can be detected in the image\n",
    "def detect_faces(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    if len(faces) > 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.79s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.19s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "instancesFile = '../annotations/instances_val2017.json'\n",
    "annFile = '../annotations/captions_val2017.json'\n",
    "cocoInstances = COCO(instancesFile)\n",
    "cocoAnn = COCO(annFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get annotation id of those within the people subset\n",
    "catIds = cocoInstances.getCatIds(catNms=['person']) # category Id of people subset\n",
    "pplIds = cocoInstances.getImgIds(catIds=catIds) # image Ids containing people category\n",
    "annIds = cocoAnn.getAnnIds(imgIds=pplIds)\n",
    "imgs = cocoInstances.loadImgs(ids=pplIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "femaleIndicators = set(['woman', 'women', 'lady', 'girl', 'girls', 'female', 'her'])\n",
    "maleIndicators = set(['male', 'man', 'boy', 'boys', 'men', 'guy', 'dude', 'his'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgId = []\n",
    "count = 0\n",
    "with open('../annotations/faceblockNeutral.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['image_id', 'caption'])\n",
    "    for img in imgs:\n",
    "        resp = urllib.request.urlopen(img['coco_url'])\n",
    "        image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
    "        image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "        if detect_faces(image):\n",
    "            continue\n",
    "        else:\n",
    "            imgId.append(img['id'])\n",
    "            annIds = cocoAnn.getAnnIds(imgIds=[img['id']])\n",
    "            anns = cocoAnn.loadAnns(annIds)\n",
    "            for ann in anns:\n",
    "                if len(set.intersection(femaleIndicators, ann)) > 0 \\\n",
    "                    or len(set.intersection(maleIndicators, ann)) > 0:\n",
    "                    writer.writerow([img['id'], ann])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find images where gender is being assumed\n",
    "Replace the gendered assumptions either with gender neutral or female indicative language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender Assumed Images: 1475\n"
     ]
    }
   ],
   "source": [
    "total_count = 0\n",
    "with open('../annotations/faceblockNeutral.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['image_id', 'caption'])\n",
    "    for img in imgId:\n",
    "        count = 0\n",
    "        annIds = cocoAnn.getAnnIds(imgIds=[img])\n",
    "        anns = cocoAnn.loadAnns(annIds)\n",
    "        for ann in anns:\n",
    "            caption = ann['caption'].split()\n",
    "            if len(set.intersection(femaleIndicators, set(caption))) > 0 \\\n",
    "            or len(set.intersection(maleIndicators, set(caption))) > 0:\n",
    "                writer.writerow([img, ann['caption']])\n",
    "                count = 1\n",
    "        if count == 1:\n",
    "            total_count += 1\n",
    "print('Gender Assumed Images: {0}'.format(total_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change from gender assumed to gender neutral language\n",
    "df = pd.read_csv('../annotations/faceblockNeutral.csv')\n",
    "captions = df['caption']\n",
    "new_captions = []\n",
    "for caption in captions:\n",
    "    caption = caption.lower()\n",
    "    if len(set.intersection(femaleIndicators, set(caption.split()))) > 0:\n",
    "        female_words = set.intersection(femaleIndicators, set(caption.split()))\n",
    "        while len(female_words) > 0:\n",
    "            female_word = female_words.pop()\n",
    "            if female_word is 'women':\n",
    "                caption = caption.replace(female_word, \"people\") \n",
    "            elif female_word is 'her':\n",
    "                caption = caption.replace(female_word, \"their\") \n",
    "            elif female_word is 'she':\n",
    "                caption = caption.replace(female_word, \"they\") \n",
    "            else:\n",
    "                caption = caption.replace(female_word, \"person\")\n",
    "    if len(set.intersection(maleIndicators, set(caption.split()))) > 0:\n",
    "        male_words = set.intersection(maleIndicators, set(caption.split()))\n",
    "        while len(male_words) > 0:\n",
    "            male_word = male_words.pop()\n",
    "            if male_word is 'men':\n",
    "                caption = caption.replace(male_word, \"people\") \n",
    "            elif male_word is 'his':\n",
    "                caption = caption.replace(male_word, \"their\") \n",
    "            elif female_word is 'he':\n",
    "                caption = caption.replace(female_word, \"they\") \n",
    "            else:\n",
    "                caption = caption.replace(male_word, \"person\")\n",
    "    new_captions.append(caption)\n",
    "df['new_caption'] = new_captions\n",
    "df.to_csv('../annotations/faceblockNeutral.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male Assumed Images: 1128\n"
     ]
    }
   ],
   "source": [
    "total_count = 0\n",
    "with open('../annotations/faceblockMale.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['image_id', 'caption'])\n",
    "    for img in imgId:\n",
    "        count = 0\n",
    "        annIds = cocoAnn.getAnnIds(imgIds=[img])\n",
    "        anns = cocoAnn.loadAnns(annIds)\n",
    "        for ann in anns:\n",
    "            caption = ann['caption'].split()\n",
    "            if len(set.intersection(maleIndicators, set(caption))) > 0:\n",
    "                writer.writerow([img, ann['caption']])\n",
    "                count = 1\n",
    "        if count == 1:\n",
    "            total_count += 1\n",
    "print('Male Assumed Images: {0}'.format(total_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change from male assumed to female assumed language\n",
    "df = pd.read_csv('../annotations/faceblockMale.csv')\n",
    "captions = df['caption']\n",
    "new_captions = []\n",
    "for caption in captions:\n",
    "    caption = caption.lower()\n",
    "    if len(set.intersection(maleIndicators, set(caption.split()))) > 0 and len(set.intersection(femaleIndicators, set(caption.split()))) == 0:\n",
    "        male_words = set.intersection(maleIndicators, set(caption.split()))\n",
    "        while len(male_words) > 0:\n",
    "            male_word = male_words.pop()\n",
    "            if male_word is 'men':\n",
    "                caption = caption.replace(male_word, \"women\") \n",
    "            elif male_word is 'his':\n",
    "                caption = caption.replace(male_word, \"her\") \n",
    "            elif female_word is 'he':\n",
    "                caption = caption.replace(female_word, \"she\")                 \n",
    "            else:\n",
    "                caption = caption.replace(male_word, \"woman\")\n",
    "    caption.replace(\"wowoman\", \"woman\")\n",
    "    new_captions.append(caption)\n",
    "df['new_caption'] = new_captions\n",
    "df.to_csv('../annotations/faceblockMale.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createAnnFile(df, filename):\n",
    "    captions = list(df['new_caption'])\n",
    "    image_id = list(df['image_id'])\n",
    "    visited = {}\n",
    "    output = {\"annotations\": [], \"images\": []}\n",
    "    for index, i in enumerate(image_id):\n",
    "        if i not in visited:\n",
    "            visited[i] = True\n",
    "            output['images'].append({\"id\": int(i),\"file_name\": 'COCO_val2014_' + str(i).zfill(12) + \".jpg\"})\n",
    "        output[\"annotations\"].append({\"image_id\": int(i), \"caption\": captions[index].strip()})\n",
    "    print(len(visited.keys()))\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(output, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1128\n"
     ]
    }
   ],
   "source": [
    "output = createAnnFile(df, '../annotations/blockMale.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
